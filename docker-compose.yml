version: '3.8'

services:
  pytorch:
    build:
      context: ./pytorch
      dockerfile: Dockerfile
    container_name: akamine-pytorch
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - ./pytorch:/workspace
    ports:
      - "8898:8888" # Jupyter ノートブックを使用する場合
    command: /bin/bash
    stdin_open: true
    tty: true

  tensorflow:
    build:
      context: ./tensorflow
      dockerfile: Dockerfile
    container_name: akamine-tensorflow
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH
    volumes:
      - ./tensorflow:/workspace
    x-develop:  # ここにwatch設定を追加
      watch:
        - action: sync
          path: .
          target: /app
    ports:
      - "8899:8888" # Jupyter ノートブックを使用する場合
    command: /bin/bash
    stdin_open: true
    tty: true

